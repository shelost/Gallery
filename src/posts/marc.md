---
series: History
type: blog
title: The Markings Abstraction & Reasoning Corpus
description: Article
blurb: "A more high-resolution dataset for AI reasoning evals, based on ARC"
card: null
preview: null
rating: 4
date: 'May 1, 2022'
author: 'Dant√®s'
theme: dark
categories:
  - figma
published: true
---

This is a preview of MARC, an AI reasoning evaluation dataset I was developing as an undergradate under the supervision of Prof. Kevin Ellis at the Learning & Recursion Lab @ Cornell.

Based on the ARC challenge, our goal with MARC was to create a dataset of line-based puzzles rather than a grid, under the hypothesis that this setup would test an AI's purely visual and reasoning skills more thoroughly than ARC's grid layout (which is inherently more friendly to computers).

We made 200+ questions, which we presented briefly to the CS department in order to move forward with the research.

Unfortunately, my Cornell email account was revoked without notice, under which all of this data was being stored. So the following puzzles, which I managed to salvage because they were saved in a separate Google Slides presentation, are all that is left of the MARC dataset.

![alt text](img/MARC-3.png "The MARC Homepage")
![alt text](img/MARC-1.png "")
![alt text](img/MARC-2.png "")


One day, I hope to return to developing similar datasets that are simultaneously fun, beautiful, and relevant to the development of AI systems that can truly reason without neededing to be pre-trained on large amounts of data.